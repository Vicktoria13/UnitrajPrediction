LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/sdi-2023-01/venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
  | Name                | Type      | Params
--------------------------------------------------
0 | stacked_transformer | STF       | 2.6 M
1 | subgraph            | LaneNet   | 2.5 K
2 | criterion           | Criterion | 0
--------------------------------------------------
2.6 M     Trainable params
0         Non-trainable params
2.6 M     Total params
10.460    Total estimated model params size (MB)
/home/sdi-2023-01/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 19 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Sanity Checking DataLoader 0:   0%|                                                                                                                   | 0/2 [00:00<?, ?it/s]tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
       device='cuda:0', dtype=torch.int32)
Get loss: torch.Size([32, 60, 2]) torch.Size([32, 60, 1]) torch.Size([32])
Sanity Checking DataLoader 0:  50%|█████████████████████████████████████████████████████▌                                                     | 1/2 [00:01<00:01,  0.52it/s]tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
       device='cuda:0', dtype=torch.int32)
/home/sdi-2023-01/venv/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
/home/sdi-2023-01/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('train/loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/home/sdi-2023-01/venv/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
Get loss: torch.Size([32, 60, 2]) torch.Size([32, 60, 1]) torch.Size([32])
Epoch 0:   0%|                                                                                                                                     | 0/1558 [00:00<?, ?it/s]tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
       device='cuda:0', dtype=torch.int32)
Get loss: torch.Size([16, 60, 2]) torch.Size([16, 60, 1]) torch.Size([16])
Epoch 0:   0%|                                                                                                                 | 1/1558 [00:00<24:10,  1.07it/s, v_num=0zp1]tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
       device='cuda:0', dtype=torch.int32)
Get loss: torch.Size([16, 60, 2]) torch.Size([16, 60, 1]) torch.Size([16])
Epoch 0:   0%|▏                                                                                                                | 2/1558 [00:02<32:06,  0.81it/s, v_num=0zp1]tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
       device='cuda:0', dtype=torch.int32)
Get loss: torch.Size([16, 60, 2]) torch.Size([16, 60, 1]) torch.Size([16])
Epoch 0:   0%|▏                                                                                                                | 3/1558 [00:03<32:15,  0.80it/s, v_num=0zp1]tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
       device='cuda:0', dtype=torch.int32)
Get loss: torch.Size([16, 60, 2]) torch.Size([16, 60, 1]) torch.Size([16])
Epoch 0:   0%|▎                                                                                                                | 4/1558 [00:04<31:17,  0.83it/s, v_num=0zp1]tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
       device='cuda:0', dtype=torch.int32)
Get loss: torch.Size([16, 60, 2]) torch.Size([16, 60, 1]) torch.Size([16])
Epoch 0:   0%|▎                                                                                                                | 5/1558 [00:06<31:10,  0.83it/s, v_num=0zp1]tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
       device='cuda:0', dtype=torch.int32)
Get loss: torch.Size([16, 60, 2]) torch.Size([16, 60, 1]) torch.Size([16])
Epoch 0:   0%|▍                                                                                                                | 6/1558 [00:07<31:46,  0.81it/s, v_num=0zp1]tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
       device='cuda:0', dtype=torch.int32)
Get loss: torch.Size([16, 60, 2]) torch.Size([16, 60, 1]) torch.Size([16])
Epoch 0:   0%|▌                                                                                                                | 7/1558 [00:09<33:34,  0.77it/s, v_num=0zp1]tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
       device='cuda:0', dtype=torch.int32)
/home/sdi-2023-01/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...