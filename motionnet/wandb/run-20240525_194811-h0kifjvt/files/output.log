LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/sdi-2023-01/venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
  | Name                | Type      | Params
--------------------------------------------------
0 | stacked_transformer | STF       | 2.6 M
1 | subgraph            | LaneNet   | 2.5 K
2 | criterion           | Criterion | 0
--------------------------------------------------
2.6 M     Trainable params
0         Non-trainable params
2.6 M     Total params
10.460    Total estimated model params size (MB)
/home/sdi-2023-01/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 19 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Sanity Checking DataLoader 0:   0%|                                                                                                                                                                   | 0/2 [00:00<?, ?it/s]
/home/sdi-2023-01/venv/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
/home/sdi-2023-01/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:999: UserWarning: Using a target size (torch.Size([32, 60, 2])) that is different to the input size (torch.Size([32, 32, 60, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
Sanity Checking DataLoader 0:   0%|                                                                                                                                                                   | 0/2 [00:00<?, ?it/s]pred_traj torch.Size([32, 6, 60, 2])
ground_truth torch.Size([32, 60, 4])
gt_traj torch.Size([32, 60, 2])
FDE torch.Size([32, 6])
MIN FDE INDEX torch.Size([32])
Sanity Checking DataLoader 0:  50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 1/2 [00:02<00:02,  0.33it/s]
Sanity Checking DataLoader 0:  50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 1/2 [00:02<00:02,  0.33it/s]pred_traj torch.Size([32, 6, 60, 2])
ground_truth torch.Size([32, 60, 4])
gt_traj torch.Size([32, 60, 2])
FDE torch.Size([32, 6])
MIN FDE INDEX torch.Size([32])
/home/sdi-2023-01/venv/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
/home/sdi-2023-01/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:999: UserWarning: Using a target size (torch.Size([16, 60, 2])) that is different to the input size (torch.Size([16, 16, 60, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.huber_loss(input, target, reduction=self.reduction, delta=self.delta)
Epoch 0:   0%|                                                                                                                                                                                     | 0/1558 [00:00<?, ?it/s]pred_traj torch.Size([16, 6, 60, 2])
ground_truth torch.Size([16, 60, 4])
gt_traj torch.Size([16, 60, 2])
FDE torch.Size([16, 6])
MIN FDE INDEX torch.Size([16])
Epoch 0:   0%|                                                                                                                                                                 | 1/1558 [00:01<51:21,  0.51it/s, v_num=fjvt]pred_traj torch.Size([16, 6, 60, 2])
ground_truth torch.Size([16, 60, 4])
gt_traj torch.Size([16, 60, 2])
FDE torch.Size([16, 6])
MIN FDE INDEX torch.Size([16])
Epoch 0:   0%|▏                                                                                                                                                                | 2/1558 [00:03<45:58,  0.56it/s, v_num=fjvt]
/home/sdi-2023-01/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...